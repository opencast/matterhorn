<html>
<head>
<title>Hold for export</title>
<link rel="stylesheet" type="text/css" href="/admin/css/jquery-ui/jquery-ui.css" />
<link rel="stylesheet" type="text/css" href="/admin/css/jquery-ui/jquery-ui-admin.css" />   
<link rel="stylesheet" type="text/css" href="/admin/css/admin.css">
<script type="text/javascript" src="/admin/js/jquery/jquery.js"></script>
<script type="text/javascript" src="/admin/js/jquery/jquery-ui.js"></script>    
<script type="text/javascript" src="/admin/js/oc.utils.js"></script>
<script type="text/javascript" src="/admin/js/ext/trimpath.js"></script>
<script type="text/javascript">
  // Used to get the workflow id of the current operation that is executing.
  var postData = {
    'id': parent.document.getElementById("holdWorkflowId").value
  };
	
  var templateFrames = '{for f in frames}' +
                                '<div ' +
                                    'id="${f.id}" ' +
                                    'class="source-frame" ' +
                                    'style="width:100%; height:20%; background-color: blue;" ' +
                                 '>' +
                                  '<span id="${f.id}_width" style="display: none">${f.width}</span>' +
                                  '<span id="${f.id}_height" style="display: none">${f.height}</span>' +
                                '</div><p></p>' +
                              '{/for}';
  // Used when the user wants to try and determine the source video type automatically.
  var vgaDecodebin = "decodebin2 name=VgaDecodeBin";
  var cameraDecodebin = "decodebin2 name=CameraDecodeBin";
  // Used to decode MPEG 2 Program Stream video sources (like capture agent media.)
  var vgaMpegPS = "mpegpsdemux name=VgaPSDemux ! mpeg2dec name=VgaMpeg2Dec";
  var cameraMpegPS = "mpegpsdemux name=CameraPSDemux ! mpeg2dec name=CameraMpeg2Dec";
  // Used to decode MPEG 2 Transport Stream video sources. 
  var vgaMpegTS = "mpegtsdemux name=VgaTSDemux ! mpeg2dec name=VgaMpeg2Dec";
  var cameraMpegTS = "mpegtsdemux name=CameraTSDemux ! mpeg2dec name=CameraMpeg2Dec";
  // Used to decode x264 and H.264 AVC video sources inside an mp4 or mov container.  
  var vgaMp4x264 = "qtdemux name=VgaQTDemux ! ffdec_h264 name=VgaH264Dec";
  var cameraMp4x264 = "qtdemux name=CameraQTDemux ! ffdec_h264 name=CameraH264Dec";
    
  // This template is used when the media package has Camera, VGA and Audio sources and the user wants all three. 
  var cameraScreenAudioTemplate = "filesrc location={VGA} ! {VgaDECODE} ! videorate ! video/x-raw-yuv,framerate=\(fraction\)30/1 ! " +
    "videobox border-alpha=1 top=0 bottom=0 left=-{CameraWIDTH} ! " +
    "videomixer name=mix sink_0::alpha=1 sink_1::alpha=1 background=black ! " +
    "{VIDEOSCALE}" + 
    "ffmpegcolorspace ! x264enc pass=5 quantizer=25 speed-preset=6 profile=3 ! queue name=camera ! mp4mux name=mux ! filesink location={OUTPUTFILE} " +
    "filesrc location={CAMERA} ! {CameraDECODE} ! videorate ! video/x-raw-yuv,framerate=\(fraction\)30/1 ! mix. ";
    
  // This template is used when the user only wants VGA and Audio sources or that is all the media package has. 
  var screenAudioTemplate = "filesrc location={VGA} ! {VgaDECODE} ! videorate ! video/x-raw-yuv,framerate=\(fraction\)30/1 ! " +
    "{VIDEOSCALE}" + 
    "ffmpegcolorspace ! x264enc pass=5 quantizer=25 speed-preset=6 profile=3 ! queue name=camera ! mp4mux name=mux ! filesink location={OUTPUTFILE} ";
    
  // This template is used when the user only wants Camera and Audio sources or that is all the media package has. 
  var cameraAudioTemplate = "filesrc location={CAMERA} ! {CameraDECODE} ! videorate ! video/x-raw-yuv,framerate=\(fraction\)30/1 ! " +
    "{VIDEOSCALE}" + 
    "ffmpegcolorspace ! x264enc pass=5 quantizer=25 speed-preset=6 profile=3 ! queue name=camera ! mp4mux name=mux ! filesink location={OUTPUTFILE} ";
 
  var audioTemplate = "filesrc location={AUDIO} ! decodebin2 name=AudioDecodeBin ! audioconvert ! audio/x-raw-int,rate=44100,channels=2 ! faac bitrate=160000 profile=2 ! queue name=audio ! mux.";

  // If the user wants the original video source size for editing this is the choice. 
  var original = "";
  // If this video is going to end up on a mobile platform it needs to be scaled smaller for older mobiles. 
  var mobile = "videoscale ! video/x-raw-yuv,width=640,height=480 ! ";
  // If the video will end up on tablets then this will scale it appropriately saving video size even if it can handle more.
  var tablet = "videoscale ! video/x-raw-yuv,width=1024,height=768 ! ";
  // This will scale the video output to 720p. 
  var hd = "videoscale ! video/x-raw-yuv,width=1280,height=720 ! ";
  // This will scale the video output to 1080p. 
  var fullhd = "videoscale ! video/x-raw-yuv,width=1920,height=1080 ! ";
	
  // The temporary output file location. 
  var outputFile = "";
  // The replacement variable for the presentation or VGA source. 
  var presentation = "";
  // The replacement variable for the presenter or Camera source. 
  var presenter = "";
  // The width of the camera source in case to slide it in beside the VGA source in case both are used. 
  var presenterWidth = "";
  // The replacement variable for the audio source. 
  var audio = "";
  // The title of this media package. 
  var title = "";
  // The workflow id of this workflow operation. 
  var id = "";

  $(document).ready(function() {
    id = postData.id;             
    // load preview player and metadata
    $.ajax({
      url: '/workflow/instance/' + id + '.json',
      dataType: 'json', // or XML..
      success: function(data) {
        var tracks = data.workflow.mediapackage.media.track;
        if (!$.isArray(tracks)) {
          tracks = [tracks];
	}
	
        var frames = [];
        for (var i = 0; i < tracks.length; i++) {
          var track = tracks[i];
          if (track.type.indexOf("/source") != -1 && track.video != undefined) {
            frames.push({id: track.id, width: track.video.resolution.split("x")[0], height: track.video.resolution.split("x")[1]});
          }
        }
	
        var sources = {frames: frames};
	processedTemplateData = templateFrames.process(sources);
	$("#source-frames").html(processedTemplateData);
	$(".source-frame").draggable({
          containment: $("#holdStateUI"),
          stack: ".source-frame",
          revert: 'invalid'
	});
     
        $(".droppable-area").droppable({
          accept: '.source-frame',
          tolerance: 'fit'
        });
      }
    });
        
	
    // Determine the substitution variables for the Camera, VGA and Audio tracks from the media package.
    $.ajax({
      url: '/workflow/instance/' + id + '.json',
      dataType: 'json', // or XML..
      success: function(data) {
        title = data.workflow.mediapackage.title;
        var tracks = data.workflow.mediapackage.media.track;
        if (!$.isArray(tracks)) {
          tracks = [tracks];
        }
	
        var frames = [];
        for (var i = 0; i < tracks.length; i++) {
          var track = tracks[i];
          // Find presenter track. 
          if (track.type.indexOf("presenter/source") != -1 && track.video != undefined) {
            presenter = "${.vars[\"" + track.id + "\"]}";
            presenterWidth = track.video.resolution.split("x")[0];
          } 
          // Find presentation track. 
          else if (track.type.indexOf("presentation/source") != -1 && track.video != undefined) {
            presentation = "${.vars[\"" + track.id + "\"]}";
          } 
          // Find audio. 
          else if (track.type.indexOf("/source") != -1 && track.audio != undefined) {
            audio = "${.vars[\"" + track.id + "\"]}";
          }
        }
        updateTemplate();
      }
    });
		
    $("input:radio").click(function(){
      updateTemplate();
    });
  });

  function hideUnusableOptions () {
    if (presentation === "") {
      $("#CameraScreenAudio").attr("disabled", "disabled");
      $("#ScreenAudio").attr("disabled", "disabled");
      $("#CameraAudio").attr("checked", true);
    }
    else if (presenter === "") {
      $("#CameraScreenAudio").attr("disabled", "disabled");
      $("#CameraAudio").attr("disabled", "disabled");
      $("#ScreenAudio").attr("checked", true); 
    }
  }    

  /** Creates a gstreamer command based on radio buttons that can be selected. 
  It also creates the temporary file location**/
  function updateTemplate() {
    hideUnusableOptions();  
    var inputChecked = "";
    var sourceChecked = "";
    var scaleChecked = "";
	
    // Get the selections for each of the three radio button groups. 
    $("input:radio:checked").each(function(i){
      if(this.name == "gstreamer-input") {
        inputChecked = this.value;
      } else if (this.name == "gstreamer-sources"){
        sourceChecked = this.value;
      } else if (this.name == "gstreamer-scale") {
        scaleChecked = this.value;
      }
    });
		
    // Select the correct demuxer and decoder based on the input radio buttons. 
    var vgaInput = "";
    var cameraInput = "";
    if(inputChecked == "decodebin") {
      vgaInput = vgaDecodebin;
      cameraInput = cameraDecodebin;
    } else if(inputChecked == "mpegps") {
      vgaInput = vgaMpegPS;
      cameraInput = cameraMpegPS;
    } else if(inputChecked == "mpegts") {
      vgaInput = vgaMpegTS;
      cameraInput = cameraMpegTS;
    } else if(inputChecked == "x264") {
      vgaInput = vgaMp4x264;
      cameraInput = cameraMp4x264;
    } else {
      vgaInput = vgaDecodebin;
      cameraInput = cameraDecodebin;
    }
		
    // Select the correct template for either using Camera, VGA and Audio or just VGA and Audio
    var template = "";
    if(sourceChecked == "CameraScreenAudio") {
      template = cameraScreenAudioTemplate;
    } else if(sourceChecked == "ScreenAudio") {
      template = screenAudioTemplate;
    } else {
      template = cameraAudioTemplate;
    }
     
    if(audio !== "") {
      template = template + audioTemplate; 
    }    
		
    // Select the correct scaling for the output video. 
    var scale = "";
    if(scaleChecked == "Original") {
      scale = original;
    } else if(scaleChecked == "Mobile") {
      scale = mobile;
    } else if(scaleChecked == "Tablet") {
      scale = tablet;
    }else if(scaleChecked == "HD") {
      scale = hd;
    }else if(scaleChecked == "FullHD") {
      scale = fullhd;
    } else {
      scale = original;
    }
		
    // Generate the output file including title, Sources, Scaling and workflow id.  
    // e.g. CHEM-250-02-201201-MWF-0830_1_CameraScreenAudio_FullHDScaledCAMERA: presenter_28.mp4
    outputFile = "/tmp/" + title.replace(/ /g, "_") + "_" + sourceChecked + "_" + scaleChecked + "Scaled_" + id + ".mp4";	
    $("#gstreamer-output-files").attr("value", outputFile);
	
    // Replace all selected values in the template. 
    var gstreamerCommand = template;
    gstreamerCommand = substitute(gstreamerCommand, {VGA: presentation, CAMERA: presenter, AUDIO: audio, 
      VgaDECODE: vgaInput, CameraDECODE: cameraInput, VIDEOSCALE: scale, CameraWIDTH: presenterWidth, OUTPUTFILE: outputFile});
    $("#gstreamer-line").attr("value", gstreamerCommand);
  }
	
  /** Replaces a variable in a string like {seriesID} with a dictionary entry [{ seriesID: "My Series ID"}]
  str is the string to replace the variables in.
  sub is the dictionary. 
  **/
  substitute = function(str, sub) {
    return str.replace(/\{(.+?)\}/g, function($0, $1) {
      return $1 in sub ? sub[$1] : $0;
    });
  };
	
  /**
   Continues the Workflow
  */
  function continueWorkflow(){
    postData["org.opencastproject.workflow.config.gstreamer"] = $("#gstreamer-line").val();
    postData["org.opencastproject.workflow.config.gstreamer.outputfiles"] = $("#gstreamer-output-files").val();
    postData["org.opencastproject.workflow.config.gstreamer.acl"] = $("#acl").val();
    parent.ocRecordings.continueWorkflow(postData);
  }
            
  function cancel(){
    window.parent.location.href = "/admin";
  }
</script>
</head>
<body>
  <div class="lectureInfo" style="">
    <h2 id="info-title"></h2>
    <h4 id="info-creator"></h4>
    <h4 id="info-series"></h4>
  </div>

  <div class="holdStateUI" style="height: 100%; width: 100%;">
    <h1>Export Media</h1>
    <h3>Video Input Type</h3>
    <ul>
      <li>
        <Input type = radio Name = gstreamer-input Value = "decodebin">
	Automatic (decodebin2)
      </li>
      <li>
        <Input type = radio Name = gstreamer-input Value = "mpegps" checked>
        MPEG 2 Program Stream (Default for capture agent, mpegpsdemux ! mpeg2dec)
      </li>
      <li>
        <Input type = radio Name = gstreamer-input Value = "mpegts">
        MPEG 2 Transport Stream (Mpeg2 from another source, mpegtsdemux ! mpeg2dec)
      </li>
      <li>
        <Input type = radio Name = gstreamer-input Value = "x264">
        H.264 AVC (x264 or H.264 in a mp4 or mov container, qtdemux ! ffdec_h264)
      </li>
    </ul>
    </br>
    <h3>Sources</h3>
    <ul>
      <li>
        <Input type = radio Name = gstreamer-sources Value = "CameraScreenAudio" id="CameraScreenAudio" checked="yes">
        Camera, Screen and Audio
      </li>
      <li>
        <Input type = radio Name = gstreamer-sources Value = "ScreenAudio" id="ScreenAudio">
        Screen and Audio
      </li>
      <li>
        <Input type = radio Name = gstreamer-sources Value = "CameraAudio" id="CameraAudio">
        Camera and Audio
      </li>
    </ul>
    </br>
    <h3>Output Scale</h3>
    <ul>
      <li>
        <Input type = radio Name = gstreamer-scale Value = "Original" checked>
	Original Resolution
      </li>
      <li>
        <Input type = radio Name = gstreamer-scale Value = "Mobile">
        Mobile (Scaled to 640 x 480)
      </li>
      <li>
        <Input type = radio Name = gstreamer-scale Value = "Tablet">
        Tablet (Scaled to 1024 x 768)
      </li>
      <li>
        <Input type = radio Name = gstreamer-scale Value = "HD">
        Scaled to HD (720p, 1280x720)
      </li>
      <li>
        <Input type = radio Name = gstreamer-scale Value = "FullHD">
        Scaled to Full HD (1080p, 1920x1080p)
      </li>
    </ul>
    </br>

    <h3>Roles able to see output videos (e.g. ROLE_ADMIN, ROLE_USER, ROLE_ANONYMOUS)</h3>
    Enter each role with its own tags e.g. &lt;roles&gt;&lt;role&gt;ROLE_ADMIN&lt;/role&gt; &lt;role&gt;ROLE_USER&lt;/role&gt; &lt;role&gt;ROLE_ANONYMOUS&lt;/role&gt;&lt;/roles&gt;
    <textarea id="acl" style="width: 100%; height: 5%;" wrap="hard" ></textarea>
    </br>
    <h3>gstreamer Command (enter without gst-launch e.g. fakesrc ! fakesink)</h3>
    Enter Gstreamer Line without gst-launch e.g. fakesrc ! fakesink
    <textarea id="gstreamer-line" style="width: 100%; height: 10%;" wrap="hard" ></textarea>
    </br>
    <h3>Temporary Output Files Paths (e.g./tmp/file1,/tmp/file2,/tmp/file3)</h3>
    Enter output filesnames (with paths) e.g. /tmp/test.mp4 and it will be added to the export download location.
    <textarea id="gstreamer-output-files" style="width: 100%; height: 5%;"></textarea>
    <div style="height: 100%; width: 100%; display: none;">
      <div id="source-frames" class="droppable-area" style="height: 100%; width: 20%; float: left;">
      </div>
      <div id="layout-area" class="droppable-area" style="height: 100%; width: 80%; float: left; border: 1px solid">
      </div>
    </div>

      <div id="actions">
        <input title="Continue processing this template" style="margin-left: 65px; margin-right: 16px; width: 160px;" onclick="continueWorkflow();" id="continueBtn" type="button" class="ui-button ui-corner-all" value="Continue processing" />
        <!-- a id="edit-link" class="secondaryButton">Edit metadata, then continue</a -->
        <a onclick="cancel()" title="Cancel" class="secondaryButton">Cancel</a>
      </div>
    </div>
  </body>
</html>
